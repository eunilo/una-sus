#!/usr/bin/env python3
"""
üîÑ Coleta e Processamento Separados - UNA-SUS
============================================

Este script implementa a separa√ß√£o completa entre coleta de dados
e processamento DEIA, garantindo integridade do database original.

üéØ ARQUITETURA:
1. üìä COLETA COMPLETA - Todos os dados UNA-SUS
2. üíæ DATABASE FIEL - Preserva√ß√£o dos dados originais
3. üîç PROCESSAMENTO DEIA - An√°lise n√£o-destrutiva
4. üìà RELAT√ìRIOS - Resultados separados

üî¨ METODOLOGIA:
- Separa√ß√£o clara de responsabilidades
- Database intacto e atualizado
- Processamento n√£o-destrutivo
- Logs detalhados de cada etapa
"""

import logging
import os
import sys
from datetime import datetime
from typing import Dict, List

from modulos.analisador_geral import AnalisadorGeral

# Importar m√≥dulos
from modulos.coletor_unasus_completo import ColetorUnasusCompleto
from modulos.processador_deia import ProcessadorDEIA


class OrquestradorColetaProcessamento:
    """
    üîÑ Orquestrador de Coleta e Processamento Separados

    Coordena coleta completa e processamento DEIA mantendo integridade.
    """

    def __init__(self):
        """
        Inicializa o orquestrador.
        """
        self.logger = self._configurar_logger()
        self.coletor = ColetorUnasusCompleto(self.logger)
        self.processador = ProcessadorDEIA(self.logger)
        self.analisador = AnalisadorGeral(self.logger)
        self.dados_coletados = []
        self.resultados_processamento = {}
        self.resultados_analise_geral = {}

    def _configurar_logger(self) -> logging.Logger:
        """
        üìù Configura o logger principal.

        Returns:
            Logger configurado
        """
        # Criar pasta de logs se n√£o existir
        os.makedirs("logs", exist_ok=True)

        # Configurar logger
        logger = logging.getLogger("OrquestradorColetaProcessamento")
        logger.setLevel(logging.INFO)

        # Handler para arquivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        fh = logging.FileHandler(f"logs/orquestrador_{timestamp}.log", encoding="utf-8")
        fh.setLevel(logging.INFO)

        # Handler para console
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)

        # Formatter
        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)

        # Adicionar handlers
        logger.addHandler(fh)
        logger.addHandler(ch)

        return logger

    def executar_coleta_completa(self) -> bool:
        """
        üìä Executa coleta completa de dados UNA-SUS.

        Returns:
            True se bem-sucedida, False caso contr√°rio
        """
        self.logger.info("üöÄ INICIANDO COLETA COMPLETA")
        self.logger.info("üìã PRINC√çPIO: Coletar TODOS os dados sem filtros")

        try:
            # Executar coleta completa
            self.dados_coletados = self.coletor.coletar_dados_completos()

            self.logger.info(
                f"‚úÖ COLETA COMPLETA FINALIZADA: {len(self.dados_coletados)} cursos"
            )
            return True

        except Exception as e:
            self.logger.error(f"‚ùå ERRO NA COLETA: {str(e)}")
            return False

    def carregar_dados_existentes(self, caminho_arquivo: str) -> bool:
        """
        üìÇ Carrega dados existentes para processamento.

        Args:
            caminho_arquivo: Caminho para o arquivo de dados

        Returns:
            True se carregado com sucesso, False caso contr√°rio
        """
        self.logger.info(f"üìÇ Carregando dados existentes: {caminho_arquivo}")

        try:
            # Carregar dados no coletor
            self.dados_coletados = self.coletor.carregar_dados_existentes(
                caminho_arquivo
            )

            if self.dados_coletados:
                self.logger.info(
                    f"‚úÖ Dados carregados: {len(self.dados_coletados)} registros"
                )
                return True
            else:
                self.logger.error("‚ùå Nenhum dado carregado")
                return False

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao carregar dados: {str(e)}")
            return False

    def executar_processamento_deia(self) -> bool:
        """
        üîç Executa processamento DEIA nos dados coletados.

        Returns:
            True se bem-sucedido, False caso contr√°rio
        """
        self.logger.info("üîç INICIANDO PROCESSAMENTO DEIA")
        self.logger.info("üìã PRINC√çPIO: An√°lise n√£o-destrutiva dos dados")

        if not self.dados_coletados:
            self.logger.error("‚ùå Nenhum dado dispon√≠vel para processamento")
            return False

        try:
            # Carregar dados no processador
            self.processador.dados_originais = self.dados_coletados

            # Executar an√°lise DEIA
            self.resultados_processamento = self.processador.processar_analise_deia()

            self.logger.info("‚úÖ PROCESSAMENTO DEIA FINALIZADO")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå ERRO NO PROCESSAMENTO: {str(e)}")
            return False

    def executar_analise_geral(
        self, tipo_analise: str = "estatistica", parametros: Dict = None
    ) -> bool:
        """
        üìä Executa an√°lise geral dos dados coletados.

        Args:
            tipo_analise: Tipo de an√°lise ('estatistica', 'categoria', etc.)
            parametros: Par√¢metros espec√≠ficos da an√°lise

        Returns:
            True se bem-sucedido, False caso contr√°rio
        """
        self.logger.info(f"üìä INICIANDO AN√ÅLISE GERAL: {tipo_analise}")
        self.logger.info("üìã PRINC√çPIO: An√°lise flex√≠vel sem comprometer dados")

        if not self.dados_coletados:
            self.logger.error("‚ùå Nenhum dado dispon√≠vel para an√°lise")
            return False

        try:
            # Carregar dados no analisador
            self.analisador.dados_originais = self.dados_coletados

            # Configurar an√°lise
            self.analisador.configurar_analise(tipo_analise, parametros)

            # Executar an√°lise
            self.resultados_analise_geral = self.analisador.executar_analise()

            # Salvar resultados
            self.analisador.salvar_resultados()

            self.logger.info("‚úÖ AN√ÅLISE GERAL CONCLU√çDA")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå Erro na an√°lise geral: {str(e)}")
            return False

    def executar_workflow_completo(
        self, executar_coleta: bool = True, caminho_dados: str = None
    ) -> Dict:
        """
        üîÑ Executa workflow completo de coleta e processamento.

        Args:
            executar_coleta: Se deve executar coleta ou usar dados existentes
            caminho_dados: Caminho para dados existentes (se n√£o executar coleta)

        Returns:
            Resultados do workflow
        """
        self.logger.info("üîÑ INICIANDO WORKFLOW COMPLETO")

        resultados_workflow = {
            "workflow": "Coleta e Processamento Separados",
            "timestamp_inicio": datetime.now().isoformat(),
            "etapas_executadas": [],
            "resultados": {},
            "status": "em_andamento",
        }

        try:
            # ETAPA 1: Coleta ou Carregamento
            if executar_coleta:
                self.logger.info("üìä ETAPA 1: Coleta Completa de Dados")
                if self.executar_coleta_completa():
                    resultados_workflow["etapas_executadas"].append("coleta_completa")
                else:
                    raise Exception("Falha na coleta de dados")
            else:
                self.logger.info("üìÇ ETAPA 1: Carregamento de Dados Existentes")
                if caminho_dados and self.carregar_dados_existentes(caminho_dados):
                    resultados_workflow["etapas_executadas"].append(
                        "carregamento_dados"
                    )
                else:
                    raise Exception("Falha no carregamento de dados")

            # ETAPA 2: Processamento DEIA
            self.logger.info("üîç ETAPA 2: Processamento DEIA")
            if self.executar_processamento_deia():
                resultados_workflow["etapas_executadas"].append("processamento_deia")
                resultados_workflow["resultados_deia"] = self.resultados_processamento
            else:
                raise Exception("Falha no processamento DEIA")

            # ETAPA 3: An√°lise Geral
            self.logger.info("üìä ETAPA 3: An√°lise Geral")
            if self.executar_analise_geral("estatistica"):
                resultados_workflow["etapas_executadas"].append("analise_geral")
                resultados_workflow["resultados_analise_geral"] = (
                    self.resultados_analise_geral
                )
            else:
                raise Exception("Falha na an√°lise geral")

            # Workflow conclu√≠do com sucesso
            resultados_workflow["status"] = "concluido"
            resultados_workflow["timestamp_fim"] = datetime.now().isoformat()

            # Gerar relat√≥rio final
            self._gerar_relatorio_workflow(resultados_workflow)

            self.logger.info("‚úÖ WORKFLOW COMPLETO FINALIZADO COM SUCESSO")

        except Exception as e:
            self.logger.error(f"‚ùå ERRO NO WORKFLOW: {str(e)}")
            resultados_workflow["status"] = "erro"
            resultados_workflow["erro"] = str(e)
            resultados_workflow["timestamp_fim"] = datetime.now().isoformat()

        return resultados_workflow

    def _gerar_relatorio_workflow(self, resultados: Dict):
        """
        üìä Gera relat√≥rio final do workflow.

        Args:
            resultados: Resultados do workflow
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        caminho_relatorio = f"relatorios/relatorio_workflow_{timestamp}.json"

        # Criar pasta se n√£o existir
        os.makedirs("relatorios", exist_ok=True)

        # Salvar relat√≥rio
        import json

        with open(caminho_relatorio, "w", encoding="utf-8") as f:
            json.dump(resultados, f, ensure_ascii=False, indent=2)

        self.logger.info(f"üìä Relat√≥rio do workflow salvo: {caminho_relatorio}")

    def mostrar_estatisticas(self):
        """
        üìà Mostra estat√≠sticas do processo.
        """
        print("\n" + "=" * 60)
        print("üìä ESTAT√çSTICAS DO PROCESSO")
        print("=" * 60)

        print(f"üìä Dados Coletados: {len(self.dados_coletados)} cursos")

        if self.resultados_processamento:
            resumo = self.resultados_processamento.get("resumo_geral", {})
            print(f"üîç Cursos com DEIA: {resumo.get('cursos_com_elementos_deia', 0)}")
            print(f"üìà Percentual DEIA: {resumo.get('percentual_deia', 0):.2f}%")

        if self.resultados_analise_geral:
            resumo_geral = self.resultados_analise_geral.get("resumo_geral", {})
            print(f"üìà Total de Cursos: {resumo_geral.get('total_cursos', 0)}")
            print(
                f"üìÇ Campos Dispon√≠veis: {len(resumo_geral.get('campos_disponiveis', []))}"
            )

        print("=" * 60)


def main():
    """
    üöÄ Fun√ß√£o principal do script.
    """
    print("üîÑ INICIANDO COLETA E PROCESSAMENTO SEPARADOS")
    print("üìã Arquitetura: Coleta Completa + Processamento DEIA")

    # Criar orquestrador
    orquestrador = OrquestradorColetaProcessamento()

    # Configurar op√ß√µes
    print("\nüéØ OP√á√ïES DISPON√çVEIS:")
    print("1. Executar coleta completa + processamento DEIA + an√°lise geral")
    print("2. Usar dados existentes + processamento DEIA + an√°lise geral")
    print("3. Apenas coleta completa")
    print("4. Apenas processamento DEIA")
    print("5. Apenas an√°lise geral")
    print("6. An√°lise geral customizada")

    try:
        opcao = input("\nEscolha uma op√ß√£o (1-6): ").strip()

        if opcao == "1":
            print("\nüöÄ Executando workflow completo...")
            resultados = orquestrador.executar_workflow_completo(executar_coleta=True)

        elif opcao == "2":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nüöÄ Executando processamento com dados existentes...")
            resultados = orquestrador.executar_workflow_completo(
                executar_coleta=False, caminho_dados=caminho
            )

        elif opcao == "3":
            print("\nüìä Executando apenas coleta completa...")
            sucesso = orquestrador.executar_coleta_completa()
            resultados = {"status": "coleta_concluida" if sucesso else "erro"}

        elif opcao == "4":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nüîç Executando apenas processamento DEIA...")
            if orquestrador.carregar_dados_existentes(caminho):
                sucesso = orquestrador.executar_processamento_deia()
                resultados = {
                    "status": "processamento_concluido" if sucesso else "erro"
                }
            else:
                resultados = {"status": "erro_carregamento"}

        elif opcao == "5":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nüìä Executando apenas an√°lise geral...")
            if orquestrador.carregar_dados_existentes(caminho):
                sucesso = orquestrador.executar_analise_geral("estatistica")
                resultados = {"status": "analise_concluida" if sucesso else "erro"}
            else:
                resultados = {"status": "erro_carregamento"}

        elif opcao == "6":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nüîß An√°lise geral customizada...")
            print(
                "Tipos dispon√≠veis: estatistica, categoria, temporal, geografica, conteudo, comparativa"
            )
            tipo = input("Tipo de an√°lise: ").strip()
            if orquestrador.carregar_dados_existentes(caminho):
                sucesso = orquestrador.executar_analise_geral(tipo)
                resultados = {
                    "status": "analise_customizada_concluida" if sucesso else "erro"
                }
            else:
                resultados = {"status": "erro_carregamento"}

        else:
            print("‚ùå Op√ß√£o inv√°lida")
            return

        # Mostrar estat√≠sticas
        orquestrador.mostrar_estatisticas()

        # Mostrar resultado
        print(f"\nüìã Status Final: {resultados.get('status', 'desconhecido')}")

        if resultados.get("status") == "concluido":
            print("‚úÖ Processo conclu√≠do com sucesso!")
            print("üìÅ Verifique as pastas 'dados/', 'resultados/' e 'relatorios/'")

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Processo interrompido pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro: {str(e)}")


if __name__ == "__main__":
    main()
