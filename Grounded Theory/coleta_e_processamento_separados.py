#!/usr/bin/env python3
"""
ğŸ”„ Coleta e Processamento Separados - UNA-SUS
============================================

Este script implementa a separaÃ§Ã£o completa entre coleta de dados
e processamento DEIA, garantindo integridade do database original.

ğŸ¯ ARQUITETURA:
1. ğŸ“Š COLETA COMPLETA - Todos os dados UNA-SUS
2. ğŸ’¾ DATABASE FIEL - PreservaÃ§Ã£o dos dados originais
3. ğŸ” PROCESSAMENTO DEIA - AnÃ¡lise nÃ£o-destrutiva
4. ğŸ“ˆ RELATÃ“RIOS - Resultados separados

ğŸ”¬ METODOLOGIA:
- SeparaÃ§Ã£o clara de responsabilidades
- Database intacto e atualizado
- Processamento nÃ£o-destrutivo
- Logs detalhados de cada etapa
"""

import logging
import os
import sys
from datetime import datetime
from typing import Dict, List

from modulos.analisador_geral import AnalisadorGeral

# Importar mÃ³dulos
from modulos.coletor_unasus_completo import ColetorUnasusCompleto
from modulos.processador_deia import ProcessadorDEIA


class OrquestradorColetaProcessamento:
    """
    ğŸ”„ Orquestrador de Coleta e Processamento Separados

    Coordena coleta completa e processamento DEIA mantendo integridade.
    """

    def __init__(self):
        """
        Inicializa o orquestrador.
        """
        self.logger = self._configurar_logger()
        self.coletor = ColetorUnasusCompleto(self.logger)
        self.processador = ProcessadorDEIA(self.logger)
        self.analisador = AnalisadorGeral(self.logger)
        self.dados_coletados = []
        self.resultados_processamento = {}
        self.resultados_analise_geral = {}

    def _configurar_logger(self) -> logging.Logger:
        """
        ğŸ“ Configura o logger principal.

        Returns:
            Logger configurado
        """
        # Criar pasta de logs se nÃ£o existir
        os.makedirs("logs", exist_ok=True)

        # Configurar logger
        logger = logging.getLogger("OrquestradorColetaProcessamento")
        logger.setLevel(logging.INFO)

        # Handler para arquivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        fh = logging.FileHandler(f"logs/orquestrador_{timestamp}.log", encoding="utf-8")
        fh.setLevel(logging.INFO)

        # Handler para console
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)

        # Formatter
        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)

        # Adicionar handlers
        logger.addHandler(fh)
        logger.addHandler(ch)

        return logger

    def executar_coleta_completa(self) -> bool:
        """
        ğŸ“Š Executa coleta completa de dados UNA-SUS.

        Returns:
            True se bem-sucedida, False caso contrÃ¡rio
        """
        self.logger.info("ğŸš€ INICIANDO COLETA COMPLETA")
        self.logger.info("ğŸ“‹ PRINCÃPIO: Coletar TODOS os dados sem filtros")

        try:
            # Executar coleta completa
            self.dados_coletados = self.coletor.coletar_dados_completos()

            self.logger.info(
                f"âœ… COLETA COMPLETA FINALIZADA: {len(self.dados_coletados)} cursos"
            )
            return True

        except Exception as e:
            self.logger.error(f"âŒ ERRO NA COLETA: {str(e)}")
            return False

    def carregar_dados_existentes(self, caminho_arquivo: str) -> bool:
        """
        ğŸ“‚ Carrega dados existentes para processamento.

        Args:
            caminho_arquivo: Caminho para o arquivo de dados

        Returns:
            True se carregado com sucesso, False caso contrÃ¡rio
        """
        self.logger.info(f"ğŸ“‚ Carregando dados existentes: {caminho_arquivo}")

        try:
            # Carregar dados no coletor
            self.dados_coletados = self.coletor.carregar_dados_existentes(
                caminho_arquivo
            )

            if self.dados_coletados:
                self.logger.info(
                    f"âœ… Dados carregados: {len(self.dados_coletados)} registros"
                )
                return True
            else:
                self.logger.error("âŒ Nenhum dado carregado")
                return False

        except Exception as e:
            self.logger.error(f"âŒ Erro ao carregar dados: {str(e)}")
            return False

    def executar_processamento_deia(self) -> bool:
        """
        ğŸ” Executa processamento DEIA nos dados coletados.

        Returns:
            True se bem-sucedido, False caso contrÃ¡rio
        """
        self.logger.info("ğŸ” INICIANDO PROCESSAMENTO DEIA")
        self.logger.info("ğŸ“‹ PRINCÃPIO: AnÃ¡lise nÃ£o-destrutiva dos dados")

        if not self.dados_coletados:
            self.logger.error("âŒ Nenhum dado disponÃ­vel para processamento")
            return False

        try:
            # Carregar dados no processador
            self.processador.dados_originais = self.dados_coletados

            # Executar anÃ¡lise DEIA
            self.resultados_processamento = self.processador.processar_analise_deia()

            self.logger.info("âœ… PROCESSAMENTO DEIA FINALIZADO")
            return True

        except Exception as e:
            self.logger.error(f"âŒ ERRO NO PROCESSAMENTO: {str(e)}")
            return False

    def executar_analise_geral(
        self, tipo_analise: str = "estatistica", parametros: Dict = None
    ) -> bool:
        """
        ğŸ“Š Executa anÃ¡lise geral dos dados coletados.

        Args:
            tipo_analise: Tipo de anÃ¡lise ('estatistica', 'categoria', etc.)
            parametros: ParÃ¢metros especÃ­ficos da anÃ¡lise

        Returns:
            True se bem-sucedido, False caso contrÃ¡rio
        """
        self.logger.info(f"ğŸ“Š INICIANDO ANÃLISE GERAL: {tipo_analise}")
        self.logger.info("ğŸ“‹ PRINCÃPIO: AnÃ¡lise flexÃ­vel sem comprometer dados")

        if not self.dados_coletados:
            self.logger.error("âŒ Nenhum dado disponÃ­vel para anÃ¡lise")
            return False

        try:
            # Carregar dados no analisador
            self.analisador.dados_originais = self.dados_coletados

            # Configurar anÃ¡lise
            self.analisador.configurar_analise(tipo_analise, parametros)

            # Executar anÃ¡lise
            self.resultados_analise_geral = self.analisador.executar_analise()

            # Salvar resultados
            self.analisador.salvar_resultados()

            self.logger.info("âœ… ANÃLISE GERAL CONCLUÃDA")
            return True

        except Exception as e:
            self.logger.error(f"âŒ Erro na anÃ¡lise geral: {str(e)}")
            return False

    def executar_workflow_completo(
        self, executar_coleta: bool = True, caminho_dados: str = None
    ) -> Dict:
        """
        ğŸ”„ Executa workflow completo de coleta e processamento.

        Args:
            executar_coleta: Se deve executar coleta ou usar dados existentes
            caminho_dados: Caminho para dados existentes (se nÃ£o executar coleta)

        Returns:
            Resultados do workflow
        """
        self.logger.info("ğŸ”„ INICIANDO WORKFLOW COMPLETO")

        resultados_workflow = {
            "workflow": "Coleta e Processamento Separados",
            "timestamp_inicio": datetime.now().isoformat(),
            "etapas_executadas": [],
            "resultados": {},
            "status": "em_andamento",
        }

        try:
            # ETAPA 1: Coleta ou Carregamento
            if executar_coleta:
                self.logger.info("ğŸ“Š ETAPA 1: Coleta Completa de Dados")
                if self.executar_coleta_completa():
                    resultados_workflow["etapas_executadas"].append("coleta_completa")
                else:
                    raise Exception("Falha na coleta de dados")
            else:
                self.logger.info("ğŸ“‚ ETAPA 1: Carregamento de Dados Existentes")
                if caminho_dados and self.carregar_dados_existentes(caminho_dados):
                    resultados_workflow["etapas_executadas"].append(
                        "carregamento_dados"
                    )
                else:
                    raise Exception("Falha no carregamento de dados")

            # ETAPA 2: Processamento DEIA
            self.logger.info("ğŸ” ETAPA 2: Processamento DEIA")
            if self.executar_processamento_deia():
                resultados_workflow["etapas_executadas"].append("processamento_deia")
                resultados_workflow["resultados_deia"] = self.resultados_processamento
            else:
                raise Exception("Falha no processamento DEIA")

            # ETAPA 3: AnÃ¡lise Geral
            self.logger.info("ğŸ“Š ETAPA 3: AnÃ¡lise Geral")
            if self.executar_analise_geral("estatistica"):
                resultados_workflow["etapas_executadas"].append("analise_geral")
                resultados_workflow["resultados_analise_geral"] = (
                    self.resultados_analise_geral
                )
            else:
                raise Exception("Falha na anÃ¡lise geral")

            # Workflow concluÃ­do com sucesso
            resultados_workflow["status"] = "concluido"
            resultados_workflow["timestamp_fim"] = datetime.now().isoformat()

            # Gerar relatÃ³rio final
            self._gerar_relatorio_workflow(resultados_workflow)

            self.logger.info("âœ… WORKFLOW COMPLETO FINALIZADO COM SUCESSO")

        except Exception as e:
            self.logger.error(f"âŒ ERRO NO WORKFLOW: {str(e)}")
            resultados_workflow["status"] = "erro"
            resultados_workflow["erro"] = str(e)
            resultados_workflow["timestamp_fim"] = datetime.now().isoformat()

        return resultados_workflow

    def _gerar_relatorio_workflow(self, resultados: Dict):
        """
        ğŸ“Š Gera relatÃ³rio final do workflow.

        Args:
            resultados: Resultados do workflow
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        caminho_relatorio = f"relatorios/relatorio_workflow_{timestamp}.json"

        # Criar pasta se nÃ£o existir
        os.makedirs("relatorios", exist_ok=True)

        # Salvar relatÃ³rio
        import json

        with open(caminho_relatorio, "w", encoding="utf-8") as f:
            json.dump(resultados, f, ensure_ascii=False, indent=2)

        self.logger.info(f"ğŸ“Š RelatÃ³rio do workflow salvo: {caminho_relatorio}")

    def mostrar_estatisticas(self):
        """
        ğŸ“ˆ Mostra estatÃ­sticas do processo.
        """
        print("\n" + "=" * 60)
        print("ğŸ“Š ESTATÃSTICAS DO PROCESSO")
        print("=" * 60)

        print(f"ğŸ“Š Dados Coletados: {len(self.dados_coletados)} cursos")

        if self.resultados_processamento:
            resumo = self.resultados_processamento.get("resumo_geral", {})
            print(f"ğŸ” Cursos com DEIA: {resumo.get('cursos_com_elementos_deia', 0)}")
            print(f"ğŸ“ˆ Percentual DEIA: {resumo.get('percentual_deia', 0):.2f}%")

        if self.resultados_analise_geral:
            resumo_geral = self.resultados_analise_geral.get("resumo_geral", {})
            print(f"ğŸ“ˆ Total de Cursos: {resumo_geral.get('total_cursos', 0)}")
            print(
                f"ğŸ“‚ Campos DisponÃ­veis: {len(resumo_geral.get('campos_disponiveis', []))}"
            )

        print("=" * 60)


def main():
    """
    ğŸš€ FunÃ§Ã£o principal do script.
    """
    print("ğŸ”„ INICIANDO COLETA E PROCESSAMENTO SEPARADOS")
    print("ğŸ“‹ Arquitetura: Coleta Completa + Processamento DEIA")

    # Criar orquestrador
    orquestrador = OrquestradorColetaProcessamento()

    # Configurar opÃ§Ãµes
    print("\nğŸ¯ OPÃ‡Ã•ES DISPONÃVEIS:")
    print("1. Executar coleta completa + processamento DEIA + anÃ¡lise geral")
    print("2. Usar dados existentes + processamento DEIA + anÃ¡lise geral")
    print("3. Apenas coleta completa")
    print("4. Apenas processamento DEIA")
    print("5. Apenas anÃ¡lise geral")
    print("6. AnÃ¡lise geral customizada")

    try:
        opcao = input("\nEscolha uma opÃ§Ã£o (1-6): ").strip()

        if opcao == "1":
            print("\nğŸš€ Executando workflow completo...")
            resultados = orquestrador.executar_workflow_completo(executar_coleta=True)

        elif opcao == "2":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nğŸš€ Executando processamento com dados existentes...")
            resultados = orquestrador.executar_workflow_completo(
                executar_coleta=False, caminho_dados=caminho
            )

        elif opcao == "3":
            print("\nğŸ“Š Executando apenas coleta completa...")
            sucesso = orquestrador.executar_coleta_completa()
            resultados = {"status": "coleta_concluida" if sucesso else "erro"}

        elif opcao == "4":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nğŸ” Executando apenas processamento DEIA...")
            if orquestrador.carregar_dados_existentes(caminho):
                sucesso = orquestrador.executar_processamento_deia()
                resultados = {
                    "status": "processamento_concluido" if sucesso else "erro"
                }
            else:
                resultados = {"status": "erro_carregamento"}

        elif opcao == "5":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nğŸ“Š Executando apenas anÃ¡lise geral...")
            if orquestrador.carregar_dados_existentes(caminho):
                sucesso = orquestrador.executar_analise_geral("estatistica")
                resultados = {"status": "analise_concluida" if sucesso else "erro"}
            else:
                resultados = {"status": "erro_carregamento"}

        elif opcao == "6":
            caminho = input("Caminho para arquivo de dados: ").strip()
            print(f"\nğŸ”§ AnÃ¡lise geral customizada...")
            print(
                "Tipos disponÃ­veis: estatistica, categoria, temporal, geografica, conteudo, comparativa"
            )
            tipo = input("Tipo de anÃ¡lise: ").strip()
            if orquestrador.carregar_dados_existentes(caminho):
                sucesso = orquestrador.executar_analise_geral(tipo)
                resultados = {
                    "status": "analise_customizada_concluida" if sucesso else "erro"
                }
            else:
                resultados = {"status": "erro_carregamento"}

        else:
            print("âŒ OpÃ§Ã£o invÃ¡lida")
            return

        # Mostrar estatÃ­sticas
        orquestrador.mostrar_estatisticas()

        # Mostrar resultado
        print(f"\nğŸ“‹ Status Final: {resultados.get('status', 'desconhecido')}")

        if resultados.get("status") == "concluido":
            print("âœ… Processo concluÃ­do com sucesso!")
            print("ğŸ“ Verifique as pastas 'dados/', 'resultados/' e 'relatorios/'")

    except KeyboardInterrupt:
        print("\nâš ï¸ Processo interrompido pelo usuÃ¡rio")
    except Exception as e:
        print(f"\nâŒ Erro: {str(e)}")


if __name__ == "__main__":
    main()
