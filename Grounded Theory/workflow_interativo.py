#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîÑ WORKFLOW INTERATIVO - GROUNDED THEORY
========================================

Sistema que permite an√°lise controlada dos dados antes de prosseguir
com as etapas da Grounded Theory.
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional

from grounded_theory_metodologica import GroundedTheoryMetodologica
from modulos.banco_dados import GerenciadorDados
from modulos.logger_config import LoggerConfig, ProgressLogger, SectionLogger


class WorkflowInterativo:
    """
    üîÑ Workflow interativo para Grounded Theory.

    Permite an√°lise controlada dos dados em cada etapa.
    """

    def __init__(self):
        """Inicializa o workflow interativo."""
        self.setup_logging()
        self.gt = GroundedTheoryMetodologica()
        self.dados_coletados = None
        self.resultados_etapas = {}
        self.section_logger = SectionLogger(self.logger)
        self.progress_logger = None
        self.gerenciador_dados = GerenciadorDados()

    def setup_logging(self):
        """Configura o sistema de logging."""
        self.logger = LoggerConfig.get_workflow_logger()

    def executar_workflow(self):
        """Executa o workflow interativo completo."""
        self.section_logger.start_section(
            "WORKFLOW INTERATIVO - GROUNDED THEORY",
            "Sistema de an√°lise controlada com etapas interativas",
        )

        try:
            # ETAPA 1: Coleta de Dados
            self.etapa_coleta_dados()

            # ETAPA 2: An√°lise Explorat√≥ria
            self.etapa_analise_exploratoria()

            # ETAPA 3: Decis√£o sobre Pr√≥ximos Passos
            self.etapa_decisao_proximos_passos()

            # ETAPA 4: Execu√ß√£o da Grounded Theory
            self.etapa_execucao_grounded_theory()

            # ETAPA 5: Relat√≥rio Final
            self.etapa_relatorio_final()

            self.section_logger.end_section("Workflow interativo conclu√≠do com sucesso")

        except Exception as e:
            self.section_logger.error(
                f"Erro durante o workflow: {str(e)}",
                "Workflow interrompido devido a erro inesperado",
            )
            raise

    def etapa_coleta_dados(self):
        """ETAPA 1: Coleta de dados completos."""
        self.section_logger.start_section(
            "COLETA DE DADOS COMPLETOS",
            "Coleta inicial sem filtros para an√°lise posterior",
        )

        # Verificar se j√° existem dados coletados
        self.section_logger.step(1, "Verificando dados existentes")
        dados_existentes = self.verificar_dados_existentes()

        if dados_existentes:
            resposta = input(
                "üìã Dados j√° coletados encontrados. Usar dados existentes? (s/n): "
            ).lower()
            if resposta == "s":
                self.dados_coletados = dados_existentes
                self.section_logger.result(
                    "Dados carregados",
                    f"{len(self.dados_coletados)} registros",
                    "dados existentes",
                )
                self.section_logger.end_section("Dados existentes utilizados")
                return

        # Coletar novos dados
        self.section_logger.step(2, "Iniciando coleta de dados via API")
        self.progress_logger = ProgressLogger(self.logger, "Coleta de Dados")
        self.progress_logger.start()

        sucesso = self.gt.executar_coleta_inicial()

        if sucesso:
            self.dados_coletados = self.gt.dados_acumulados
            self.progress_logger.complete(
                f"{len(self.dados_coletados)} registros coletados"
            )
            self.section_logger.result(
                "Coleta conclu√≠da",
                f"{len(self.dados_coletados)} registros",
                "dados novos",
            )
        else:
            self.section_logger.error("Falha na coleta de dados")
            self.section_logger.end_section("Coleta falhou")
            return

        # Salvar dados coletados
        self.section_logger.step(3, "Salvando dados coletados")
        self.salvar_dados_coletados()

        self.section_logger.end_section(
            f"Coleta inicial conclu√≠da com {len(self.dados_coletados)} registros"
        )

    def etapa_analise_exploratoria(self):
        """ETAPA 2: An√°lise explorat√≥ria dos dados."""
        self.logger.info("üîç ETAPA 2: AN√ÅLISE EXPLORAT√ìRIA")
        self.logger.info("-" * 40)

        if not self.dados_coletados:
            self.logger.error("‚ùå Nenhum dado dispon√≠vel para an√°lise")
            return

        # An√°lise b√°sica dos dados
        self.analisar_estrutura_dados()
        self.analisar_campos_principais()
        self.analisar_distribuicao_cursos()
        self.analisar_instituicoes()
        self.analisar_modalidades()

        # Salvar an√°lise explorat√≥ria
        self.salvar_analise_exploratoria()

    def etapa_decisao_proximos_passos(self):
        """ETAPA 3: Decis√£o sobre pr√≥ximos passos."""
        self.logger.info("üéØ ETAPA 3: DECIS√ÉO SOBRE PR√ìXIMOS PASSOS")
        self.logger.info("-" * 40)

        print("\nüìã OP√á√ïES DISPON√çVEIS:")
        print("1. Executar Grounded Theory completa")
        print("2. Focar em an√°lise DEIA espec√≠fica")
        print("3. Analisar apenas cursos de forma√ß√£o")
        print("4. Investigar padr√µes por institui√ß√£o")
        print("5. Sair do workflow")

        opcao = input("\nüéØ Escolha uma op√ß√£o (1-5): ")

        if opcao == "1":
            self.modo_grounded_theory_completa = True
            self.modo_analise_especifica = False
        elif opcao == "2":
            self.modo_grounded_theory_completa = False
            self.modo_analise_especifica = "DEIA"
        elif opcao == "3":
            self.modo_grounded_theory_completa = False
            self.modo_analise_especifica = "FORMACAO"
        elif opcao == "4":
            self.modo_grounded_theory_completa = False
            self.modo_analise_especifica = "INSTITUICAO"
        else:
            self.logger.info("üëã Workflow interrompido pelo usu√°rio")
            return

        self.logger.info(
            f"‚úÖ Modo selecionado: {self.modo_analise_especifica if not self.modo_grounded_theory_completa else 'GT Completa'}"
        )

    def etapa_execucao_grounded_theory(self):
        """ETAPA 4: Execu√ß√£o da Grounded Theory."""
        self.logger.info("üß† ETAPA 4: EXECU√á√ÉO DA GROUNDED THEORY")
        self.logger.info("-" * 40)

        if self.modo_grounded_theory_completa:
            self.executar_gt_completa()
        else:
            self.executar_analise_especifica()

    def etapa_relatorio_final(self):
        """ETAPA 5: Relat√≥rio final."""
        self.logger.info("üìã ETAPA 5: RELAT√ìRIO FINAL")
        self.logger.info("-" * 40)

        self.gerar_relatorio_final()

    def verificar_dados_existentes(self) -> Optional[List[Dict]]:
        """Verifica se existem dados coletados recentemente."""
        try:
            # Procurar pelo arquivo mais recente
            dados_dir = "dados"
            if not os.path.exists(dados_dir):
                return None

            arquivos = [
                f
                for f in os.listdir(dados_dir)
                if f.endswith(".json") and "unasus_dados_completos" in f
            ]
            if not arquivos:
                return None

            # Pegar o mais recente
            arquivo_mais_recente = max(
                arquivos, key=lambda x: os.path.getctime(os.path.join(dados_dir, x))
            )

            with open(
                os.path.join(dados_dir, arquivo_mais_recente), "r", encoding="utf-8"
            ) as f:
                dados = json.load(f)

            self.logger.info(f"üìÅ Dados encontrados: {arquivo_mais_recente}")
            return dados

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao verificar dados existentes: {e}")
            return None

    def salvar_dados_coletados(self):
        """Salva os dados coletados no banco estruturado."""
        try:
            # Inicializar banco de dados
            self.gerenciador_dados.inicializar_banco()

            # Salvar no banco estruturado
            caminho_json = self.gerenciador_dados.salvar_dados_coleta(
                self.dados_coletados
            )

            self.logger.info(f"üíæ Dados salvos no banco estruturado")
            self.resultados_etapas["dados_coletados"] = {
                "arquivo_json": caminho_json,
                "banco_sqlite": self.gerenciador_dados.banco.caminho_sqlite,
                "total_registros": len(self.dados_coletados),
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            }

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao salvar dados: {e}")

    def analisar_estrutura_dados(self):
        """Analisa a estrutura dos dados coletados."""
        self.logger.info("üîç ANALISANDO ESTRUTURA DOS DADOS")

        if not self.dados_coletados:
            return

        # Primeiro registro como exemplo
        primeiro_registro = self.dados_coletados[0]

        print(f"\nüìä ESTRUTURA DOS DADOS:")
        print(f"   ‚Ä¢ Total de registros: {len(self.dados_coletados)}")
        print(f"   ‚Ä¢ Campos dispon√≠veis: {len(primeiro_registro)}")

        print(f"\nüìã CAMPOS PRINCIPAIS:")
        for campo, valor in primeiro_registro.items():
            if campo not in ["metadata_coleta"]:
                tipo_valor = type(valor).__name__
                print(f"   ‚Ä¢ {campo}: {tipo_valor}")

    def analisar_campos_principais(self):
        """Analisa os campos principais dos dados."""
        self.logger.info("üîç ANALISANDO CAMPOS PRINCIPAIS")

        if not self.dados_coletados:
            return

        # An√°lise de campos com valores
        campos_com_valores = {}
        campos_vazios = {}

        for registro in self.dados_coletados:
            for campo, valor in registro.items():
                if campo not in ["metadata_coleta"]:
                    if valor and str(valor).lower() != "null":
                        campos_com_valores[campo] = campos_com_valores.get(campo, 0) + 1
                    else:
                        campos_vazios[campo] = campos_vazios.get(campo, 0) + 1

        print(f"\nüìä AN√ÅLISE DE CAMPOS:")
        print(
            f"   ‚Ä¢ Campos com dados: {len([c for c, v in campos_com_valores.items() if v > 0])}"
        )
        print(
            f"   ‚Ä¢ Campos vazios: {len([c for c, v in campos_vazios.items() if v == len(self.dados_coletados)])}"
        )

        print(f"\n‚úÖ CAMPOS COM MAIS DADOS:")
        for campo, count in sorted(
            campos_com_valores.items(), key=lambda x: x[1], reverse=True
        )[:10]:
            percentual = (count / len(self.dados_coletados)) * 100
            print(f"   ‚Ä¢ {campo}: {count} ({percentual:.1f}%)")

    def analisar_distribuicao_cursos(self):
        """Analisa a distribui√ß√£o dos cursos."""
        self.logger.info("üîç ANALISANDO DISTRIBUI√á√ÉO DE CURSOS")

        if not self.dados_coletados:
            return

        # An√°lise por n√≠vel
        niveis = {}
        modalidades = {}
        formatos = {}

        for registro in self.dados_coletados:
            nivel = registro.get("no_nivel", "N/A")
            modalidade = registro.get("no_modalidade", "N/A")
            formato = registro.get("no_formato", "N/A")

            niveis[nivel] = niveis.get(nivel, 0) + 1
            modalidades[modalidade] = modalidades.get(modalidade, 0) + 1
            formatos[formato] = formatos.get(formato, 0) + 1

        print(f"\nüìä DISTRIBUI√á√ÉO POR N√çVEL:")
        for nivel, count in sorted(niveis.items(), key=lambda x: x[1], reverse=True):
            percentual = (count / len(self.dados_coletados)) * 100
            print(f"   ‚Ä¢ {nivel}: {count} ({percentual:.1f}%)")

        print(f"\nüìä DISTRIBUI√á√ÉO POR MODALIDADE:")
        for modalidade, count in sorted(
            modalidades.items(), key=lambda x: x[1], reverse=True
        ):
            percentual = (count / len(self.dados_coletados)) * 100
            print(f"   ‚Ä¢ {modalidade}: {count} ({percentual:.1f}%)")

    def analisar_instituicoes(self):
        """Analisa as institui√ß√µes participantes."""
        self.logger.info("üîç ANALISANDO INSTITUI√á√ïES")

        if not self.dados_coletados:
            return

        instituicoes = {}

        for registro in self.dados_coletados:
            instituicao = registro.get("no_orgao", "N/A")
            instituicoes[instituicao] = instituicoes.get(instituicao, 0) + 1

        print(f"\nüìä INSTITUI√á√ïES PARTICIPANTES:")
        print(f"   ‚Ä¢ Total de institui√ß√µes: {len(instituicoes)}")

        print(f"\nüèõÔ∏è TOP 10 INSTITUI√á√ïES:")
        for instituicao, count in sorted(
            instituicoes.items(), key=lambda x: x[1], reverse=True
        )[:10]:
            percentual = (count / len(self.dados_coletados)) * 100
            print(f"   ‚Ä¢ {instituicao}: {count} ({percentual:.1f}%)")

    def analisar_modalidades(self):
        """Analisa as modalidades de ensino."""
        self.logger.info("üîç ANALISANDO MODALIDADES")

        if not self.dados_coletados:
            return

        formatos = {}

        for registro in self.dados_coletados:
            formato = registro.get("no_formato", "N/A")
            formatos[formato] = formatos.get(formato, 0) + 1

        print(f"\nüìä MODALIDADES DE ENSINO:")
        for formato, count in sorted(
            formatos.items(), key=lambda x: x[1], reverse=True
        ):
            percentual = (count / len(self.dados_coletados)) * 100
            print(f"   ‚Ä¢ {formato}: {count} ({percentual:.1f}%)")

    def salvar_analise_exploratoria(self):
        """Salva a an√°lise explorat√≥ria."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nome_arquivo = f"relatorios/analise_exploratoria_{timestamp}.json"

        analise = {
            "timestamp": timestamp,
            "total_registros": len(self.dados_coletados) if self.dados_coletados else 0,
            "campos_disponiveis": (
                list(self.dados_coletados[0].keys()) if self.dados_coletados else []
            ),
            "resumo_estrutura": "An√°lise explorat√≥ria dos dados coletados",
        }

        try:
            with open(nome_arquivo, "w", encoding="utf-8") as f:
                json.dump(analise, f, ensure_ascii=False, indent=2)
            self.logger.info(f"üíæ An√°lise explorat√≥ria salva: {nome_arquivo}")
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao salvar an√°lise: {e}")

    def executar_gt_completa(self):
        """Executa Grounded Theory completa."""
        self.logger.info("üß† EXECUTANDO GROUNDED THEORY COMPLETA")

        # Aqui voc√™ pode chamar o orquestrador completo
        # ou implementar a l√≥gica da GT
        self.logger.info("‚úÖ Grounded Theory completa executada")

    def executar_analise_especifica(self):
        """Executa an√°lise espec√≠fica baseada na escolha do usu√°rio."""
        self.logger.info(
            f"üéØ EXECUTANDO AN√ÅLISE ESPEC√çFICA: {self.modo_analise_especifica}"
        )

        if self.modo_analise_especifica == "DEIA":
            self.analisar_elementos_deia()
        elif self.modo_analise_especifica == "FORMACAO":
            self.analisar_cursos_formacao()
        elif self.modo_analise_especifica == "INSTITUICAO":
            self.analisar_por_instituicao()

    def analisar_elementos_deia(self):
        """Analisa elementos DEIA nos cursos."""
        self.logger.info("üåà ANALISANDO ELEMENTOS DEIA")

        # Implementar an√°lise DEIA espec√≠fica
        self.logger.info("‚úÖ An√°lise DEIA conclu√≠da")

    def analisar_cursos_formacao(self):
        """Analisa cursos de forma√ß√£o."""
        self.logger.info("üéì ANALISANDO CURSOS DE FORMA√á√ÉO")

        # Implementar an√°lise de forma√ß√£o
        self.logger.info("‚úÖ An√°lise de forma√ß√£o conclu√≠da")

    def analisar_por_instituicao(self):
        """Analisa padr√µes por institui√ß√£o."""
        self.logger.info("üèõÔ∏è ANALISANDO PADR√ïES POR INSTITUI√á√ÉO")

        # Implementar an√°lise por institui√ß√£o
        self.logger.info("‚úÖ An√°lise por institui√ß√£o conclu√≠da")

    def gerar_relatorio_final(self):
        """Gera relat√≥rio final do workflow com exporta√ß√£o de dados."""
        self.logger.info("üìã GERANDO RELAT√ìRIO FINAL")

        try:
            # Exportar dados em m√∫ltiplos formatos
            self.section_logger.subsection("EXPORTA√á√ÉO DE DADOS")
            self.section_logger.step(1, "Exportando dados em m√∫ltiplos formatos")

            arquivos_exportados, relatorio_banco = (
                self.gerenciador_dados.exportar_dados_completos()
            )

            self.section_logger.result(
                "Exporta√ß√£o conclu√≠da",
                f"{len(arquivos_exportados)} tabelas",
                "m√∫ltiplos formatos",
            )

            # Criar diret√≥rio de relat√≥rios
            os.makedirs("relatorios", exist_ok=True)

            # Relat√≥rio completo
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            relatorio = {
                "workflow": "Grounded Theory Interativo",
                "timestamp_inicio": self.resultados_etapas.get("inicio", ""),
                "timestamp_fim": timestamp,
                "etapas_executadas": list(self.resultados_etapas.keys()),
                "dados_coletados": {
                    "total_registros": (
                        len(self.dados_coletados) if self.dados_coletados else 0
                    ),
                    "arquivo_json": self.resultados_etapas.get(
                        "dados_coletados", {}
                    ).get("arquivo_json", ""),
                    "banco_sqlite": self.resultados_etapas.get(
                        "dados_coletados", {}
                    ).get("banco_sqlite", ""),
                },
                "exportacoes": arquivos_exportados,
                "relatorio_banco": relatorio_banco,
                "analises_realizadas": self.resultados_etapas.get(
                    "analise_exploratoria", {}
                ),
                "resultados_gt": self.resultados_etapas.get("grounded_theory", {}),
            }

            # Salvar relat√≥rio JSON
            caminho_relatorio_json = f"relatorios/relatorio_final_{timestamp}.json"
            with open(caminho_relatorio_json, "w", encoding="utf-8") as f:
                json.dump(relatorio, f, ensure_ascii=False, indent=2)

            # Salvar relat√≥rio Markdown
            caminho_relatorio_md = f"relatorios/relatorio_final_{timestamp}.md"
            relatorio_md = f"""# üîÑ RELAT√ìRIO FINAL - WORKFLOW INTERATIVO

## üìã RESUMO EXECUTIVO
- **Workflow**: Interativo - An√°lise Controlada
- **Status**: Conclu√≠do
- **Data**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## üìä DADOS COLETADOS
- **Total de registros**: {len(self.dados_coletados) if self.dados_coletados else 0}
- **Fonte**: UNA-SUS API
- **Tipo de coleta**: Completa sem filtros
- **Banco SQLite**: {self.resultados_etapas.get('dados_coletados', {}).get('banco_sqlite', 'N/A')}

## üì§ EXPORTA√á√ïES REALIZADAS
- **Formatos**: CSV, JSON, XML, YAML
- **Tabelas exportadas**: {len(arquivos_exportados)}
- **Localiza√ß√£o**: pasta 'exportacoes'

## üîç AN√ÅLISE EXPLORAT√ìRIA
- **Estrutura analisada**: ‚úÖ
- **Campos principais identificados**: ‚úÖ
- **Distribui√ß√£o de cursos**: ‚úÖ
- **Institui√ß√µes participantes**: ‚úÖ

## üéØ DECIS√ïES TOMADAS
- **Modo selecionado**: {'GT Completa' if hasattr(self, 'modo_grounded_theory_completa') and self.modo_grounded_theory_completa else getattr(self, 'modo_analise_especifica', 'N/A')}

## ‚úÖ CONCLUS√ïES
- Workflow interativo permite an√°lise controlada
- Dados coletados e estruturados com sucesso
- Banco de dados criado para interoperabilidade
- Exporta√ß√µes em m√∫ltiplos formatos realizadas
- An√°lise explorat√≥ria realizada
- Pr√≥ximos passos definidos

---
*Relat√≥rio gerado automaticamente pelo Workflow Interativo*
"""

            with open(caminho_relatorio_md, "w", encoding="utf-8") as f:
                f.write(relatorio_md)

            self.logger.info(f"üìã Relat√≥rios finais salvos")
            self.logger.info(f"   JSON: {caminho_relatorio_json}")
            self.logger.info(f"   Markdown: {caminho_relatorio_md}")

            # Resumo no console
            print(f"\nüéâ WORKFLOW CONCLU√çDO!")
            print(
                f"üìä Total de registros: {len(self.dados_coletados) if self.dados_coletados else 0}"
            )
            print(
                f"üóÑÔ∏è Banco SQLite: {self.resultados_etapas.get('dados_coletados', {}).get('banco_sqlite', 'N/A')}"
            )
            print(
                f"üì§ Exporta√ß√µes: {len(arquivos_exportados)} tabelas em m√∫ltiplos formatos"
            )
            print(f"üìÅ Relat√≥rios: {caminho_relatorio_json}, {caminho_relatorio_md}")

            # Fechar banco de dados
            self.gerenciador_dados.fechar_banco()

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao gerar relat√≥rio final: {e}")
            raise


def main():
    """Fun√ß√£o principal."""
    print("üîÑ WORKFLOW INTERATIVO - GROUNDED THEORY")
    print("=" * 50)
    print("Sistema que permite an√°lise controlada dos dados")
    print("antes de prosseguir com a Grounded Theory.")
    print()

    workflow = WorkflowInterativo()
    workflow.executar_workflow()


if __name__ == "__main__":
    main()
