# Scraper UNA-SUS

Este projeto implementa um web scraper para coletar dados de cursos e ofertas da plataforma UNA-SUS (Universidade Aberta do SUS), com foco especial em identificar cursos relacionados a Diversidade, Equidade, InclusÃ£o e Acessibilidade (DEIA).

## ğŸ“‹ DescriÃ§Ã£o

O scraper coleta informaÃ§Ãµes detalhadas sobre cursos e suas ofertas disponÃ­veis no portal da UNA-SUS, incluindo:
- InformaÃ§Ãµes bÃ¡sicas dos cursos
- Detalhes das ofertas (vagas, pÃºblico-alvo, local, formato)
- IdentificaÃ§Ã£o automÃ¡tica de cursos relacionados a DEIA
- Salvamento incremental dos dados em formato CSV

## ğŸš€ Funcionalidades

- **Coleta incremental**: Evita reprocessar cursos jÃ¡ coletados
- **DetecÃ§Ã£o DEIA**: Identifica automaticamente cursos relacionados a Diversidade, Equidade, InclusÃ£o e Acessibilidade
- **Tratamento de erros**: Sistema robusto com retry automÃ¡tico
- **Salvamento progressivo**: Salva dados a cada lote processado
- **API REST**: Utiliza a API oficial da UNA-SUS para coleta de dados

## ğŸ“ Estrutura do Projeto

```
unsa-sus/
â”œâ”€â”€ README.md                           # Este arquivo
â”œâ”€â”€ requirements.txt                    # DependÃªncias Python
â”œâ”€â”€ scraper_unasus_incremental.py      # Scraper principal
â”œâ”€â”€ teste_scraper.py                   # Script de teste
â”œâ”€â”€ import requests.py                  # MÃ³dulo de importaÃ§Ã£o
â”œâ”€â”€ .gitignore                         # Arquivos ignorados pelo Git
â”œâ”€â”€ unasus_ofertas_detalhadas.csv      # Dados coletados
â””â”€â”€ teste_unasus.csv                   # Dados de teste
```

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/eunilo/unsa-sus.git
cd unsa-sus
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ“– Como Usar

### Teste Inicial
Execute o script de teste para verificar a conectividade:
```bash
python teste_scraper.py
```

### ExecuÃ§Ã£o Completa
Para executar o scraper completo:
```bash
python scraper_unasus_incremental.py
```

O script irÃ¡:
1. Carregar dados jÃ¡ processados (se existirem)
2. Coletar novos cursos da API da UNA-SUS
3. Identificar cursos relacionados a DEIA
4. Extrair detalhes das ofertas de cada curso
5. Salvar progressivamente em `unasus_ofertas_detalhadas.csv`

## ğŸ“Š Dados Coletados

O scraper coleta as seguintes informaÃ§Ãµes:

### Cursos
- ID do curso
- Nome do curso
- DescriÃ§Ã£o
- Status
- RelaÃ§Ã£o com DEIA

### Ofertas
- ID da oferta
- CÃ³digo da oferta
- NÃºmero de vagas
- PÃºblico-alvo
- Local da oferta
- Formato
- URL da oferta

## ğŸ” Descritores DEIA

O sistema identifica automaticamente cursos relacionados aos seguintes descritores:
- Diversidade, Equidade e IntegraÃ§Ã£o
- Diversidade, Equidade, InclusÃ£o e Pertencimento
- Diversidade, Equidade, InclusÃ£o, Acessibilidade
- Diversidade, Igualdade e InclusÃ£o
- Equidade, Diversidade e InclusÃ£o
- InclusÃ£o, Diversidade, Equidade e Acessibilidade

## âš™ï¸ ConfiguraÃ§Ãµes

### ParÃ¢metros AjustÃ¡veis
- `lote = 10`: NÃºmero de cursos processados antes de salvar
- `timeout = 30`: Timeout para requisiÃ§Ãµes HTTP
- `sleep = 1`: Intervalo entre requisiÃ§Ãµes (em segundos)

### Headers HTTP
```python
headers = {
    "User-Agent": "Mozilla/5.0",
    "Content-Type": "application/json"
}
```

## ğŸ“ˆ Monitoramento

O script exibe progresso em tempo real:
- Cursos jÃ¡ processados
- PÃ¡ginas processadas
- Salvamentos incrementais
- Erros e retentativas

## ğŸ› Tratamento de Erros

- **Timeout de conexÃ£o**: Retry automÃ¡tico apÃ³s 30 segundos
- **Erro de parsing**: Log detalhado do erro
- **Arquivo CSV corrompido**: RecriaÃ§Ã£o automÃ¡tica
- **API indisponÃ­vel**: Tentativas mÃºltiplas

## ğŸ“ Formato de SaÃ­da

Os dados sÃ£o salvos em CSV com encoding UTF-8-SIG, contendo:
- Todas as colunas originais da API
- Colunas adicionais de DEIA
- Dados detalhados das ofertas
- URLs de referÃªncia

## ğŸ¤ ContribuiÃ§Ã£o

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## âš ï¸ Aviso Legal

Este scraper foi desenvolvido para fins educacionais e de pesquisa. Respeite os termos de uso da UNA-SUS e implemente delays apropriados entre requisiÃ§Ãµes para nÃ£o sobrecarregar os servidores.

## ğŸ“ Contato

- **Autor**: Eunilo
- **GitHub**: [@eunilo](https://github.com/eunilo)
- **Projeto**: [unsa-sus](https://github.com/eunilo/unsa-sus)

---

**Desenvolvido com â¤ï¸ para a comunidade de saÃºde pÃºblica brasileira** 