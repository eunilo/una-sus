<<<<<<< HEAD
# Scraper UNA-SUS - Coleta de Dados de Cursos e Ofertas

Um scraper robusto e eficiente para coletar dados detalhados de cursos e ofertas da Universidade Aberta do SUS (UNA-SUS), incluindo informaÃ§Ãµes sobre vagas, pÃºblico-alvo, formato, e anÃ¡lise de descritores DEIA.

## ğŸš€ Funcionalidades Principais

### âœ… **ExtraÃ§Ã£o Completa de Dados**
- **Cursos**: InformaÃ§Ãµes bÃ¡sicas, descriÃ§Ãµes, carga horÃ¡ria, Ã³rgÃ£os responsÃ¡veis
- **Ofertas**: Dados detalhados de cada oferta de curso
- **Vagas**: NÃºmero de vagas disponÃ­veis (extraÃ­do via API REST)
- **PÃºblico-alvo**: Perfil dos participantes
- **Formato**: Modalidade de ensino (EAD, presencial, etc.)
- **Programas de governo**: Iniciativas associadas
- **Temas e DeCs**: ClassificaÃ§Ãµes temÃ¡ticas
- **Palavras-chave**: Termos de indexaÃ§Ã£o
=======
# Scraper UNA-SUS - Cursos e Ofertas

Um scraper robusto e eficiente para coletar dados de cursos e ofertas da plataforma UNA-SUS (Universidade Aberta do SUS), com foco especial na identificaÃ§Ã£o de conteÃºdos relacionados a DEIA (Diversidade, Equidade, InclusÃ£o e Acessibilidade).
>>>>>>> a2555d3 (feat: implementaÃ§Ã£o completa com clean code e melhorias robustas)

### âœ… **AnÃ¡lise DEIA (Diversidade, Equidade, InclusÃ£o e Acessibilidade)**
- DetecÃ§Ã£o automÃ¡tica de descritores DEIA nos cursos
- AnÃ¡lise de tÃ­tulo e descriÃ§Ã£o para identificar iniciativas inclusivas
- Mapeamento de cursos com foco em diversidade e equidade

<<<<<<< HEAD
### âœ… **ExtraÃ§Ã£o Inteligente de Ofertas**
- **Ofertas ativas**: Busca automÃ¡tica de ofertas em andamento
- **Ofertas encerradas**: DetecÃ§Ã£o e extraÃ§Ã£o de ofertas finalizadas
- **API REST**: Uso de API oficial para dados precisos
- **Fallback HTML**: ExtraÃ§Ã£o alternativa via parsing de pÃ¡ginas

### âœ… **Sistema Robusto de Coleta**
- **Salvamento incremental**: Dados salvos a cada lote processado
- **Checkpoint automÃ¡tico**: Retoma de onde parou em caso de interrupÃ§Ã£o
- **Logs detalhados**: Monitoramento em tempo real do progresso
- **Tratamento de erros**: RecuperaÃ§Ã£o automÃ¡tica de falhas

## ğŸ“Š Dados Coletados

### Colunas do Dataset Final

| Coluna | DescriÃ§Ã£o | Exemplo |
|--------|-----------|---------|
| `co_seq_curso` | ID Ãºnico do curso | `44538` |
| `no_curso` | Nome do curso | `"1Âº FormaÃ§Ã£o de Preceptores para o SUS"` |
| `qt_carga_horaria_total` | Carga horÃ¡ria total | `195` |
| `co_seq_orgao` | ID do Ã³rgÃ£o responsÃ¡vel | `13` |
| `sg_orgao` | Sigla do Ã³rgÃ£o | `"UNIFESP"` |
| `no_orgao` | Nome completo do Ã³rgÃ£o | `"Universidade Federal de SÃ£o Paulo"` |
| `no_formato` | Formato do curso | `"Ensino a DistÃ¢ncia"` |
| `no_nivel` | NÃ­vel educacional | `"ExtensÃ£o"` |
| `no_modalidade` | Modalidade | `"AperfeiÃ§oamento"` |
| `ds_imagem` | URL da imagem do curso | `"https://..."` |
| `status` | Status atual | `"Oferta encerrada"` |
| `status_ordem` | Ordem do status | `3` |
| `tem_deia` | Possui descritores DEIA | `"Sim"` / `"NÃ£o"` |
| `deia_encontrado` | Descritor DEIA especÃ­fico | `"Diversidade, Equidade e InclusÃ£o"` |
| `id_oferta` | ID Ãºnico da oferta | `416264` |
| `codigo_oferta` | CÃ³digo da oferta | `416264` |
| **`vagas`** | **NÃºmero de vagas disponÃ­veis** | **`195`** |
| `publico_alvo` | PÃºblico-alvo da oferta | `"Profissionais da saÃºde..."` |
| `local_oferta` | Local da oferta | `"EAD"` |
| `formato` | Formato da oferta | `"Ensino a DistÃ¢ncia"` |
| `programas_governo` | Programas de governo associados | `"UNA-SUS, EspecializaÃ§Ã£o"` |
| `temas` | Temas abordados | `"SaÃºde PÃºblica"` |
| `decs` | ClassificaÃ§Ã£o DeCs | `"Medicina"` |
| `descricao_oferta` | DescriÃ§Ã£o detalhada da oferta | `"1Âª Oferta - FormaÃ§Ã£o..."` |
| `palavras_chave` | Palavras-chave da oferta | `"FormaÃ§Ã£o de Preceptores"` |
| `url_oferta` | URL da pÃ¡gina da oferta | `"https://..."` |
| `erro` | Erro durante coleta (se houver) | `"Sem ofertas encontradas"` |
=======
### âœ¨ Principais Recursos
- **Scraping Inteligente**: Coleta dados de cursos e ofertas da UNA-SUS
- **AnÃ¡lise DEIA**: Identifica automaticamente conteÃºdos relacionados a Diversidade, Equidade, InclusÃ£o e Acessibilidade
- **Processamento Incremental**: Salva dados progressivamente para evitar perda de informaÃ§Ãµes
- **Sistema de Checkpoint**: Permite retomar o scraping de onde parou
- **Logging Detalhado**: Acompanhamento completo do progresso
- **ValidaÃ§Ã£o de Dados**: Verifica integridade e qualidade dos dados coletados
- **ExtraÃ§Ã£o de DescriÃ§Ãµes**: Busca descriÃ§Ãµes completas em pÃ¡ginas individuais dos cursos
- **Busca por Ofertas Encerradas**: Inclui ofertas que podem estar ocultas

### ğŸ”§ Ferramentas Auxiliares
- **Monitor em Tempo Real**: Acompanhe o progresso do scraper
- **Validador de Dados**: Analise e limpe os dados coletados
- **Teste de PaginaÃ§Ã£o**: Debug da API da UNA-SUS

## ğŸ“Š Dados Coletados

### InformaÃ§Ãµes dos Cursos
- **IdentificaÃ§Ã£o**: `co_seq_curso`, `id_curso`, `co_curso`
- **Dados BÃ¡sicos**: `no_curso` (nome), `qt_carga_horaria_total`
- **OrganizaÃ§Ã£o**: `co_seq_orgao`, `sg_orgao`, `no_orgao`
- **CaracterÃ­sticas**: `no_formato`, `no_nivel`, `no_modalidade`
- **MÃ­dia**: `ds_imagem`
- **Status**: `status`, `status_ordem`
- **DescriÃ§Ã£o**: `ds_curso` (extraÃ­da da pÃ¡gina do curso quando necessÃ¡rio)
- **Qualidade**: `curso_incompleto` (marca cursos sem descriÃ§Ã£o)

### InformaÃ§Ãµes das Ofertas
- **IdentificaÃ§Ã£o**: `id_oferta`, `codigo_oferta`
- **Detalhes**: `vagas`, `publico_alvo`, `local_oferta`
- **Formato**: `formato`
- **Programas**: `programas_governo`
- **ClassificaÃ§Ã£o**: `temas`, `decs`, `palavras_chave`
- **DescriÃ§Ã£o**: `descricao_oferta`

### AnÃ¡lise DEIA
- **Indicador**: `tem_deia` (Sim/NÃ£o)
- **Descritor**: `deia_encontrado` (descritor especÃ­fico encontrado)

### Campos de Controle
- **URL**: `url_oferta`
- **Erros**: `erro` (quando aplicÃ¡vel)

## ğŸ¯ Descritores DEIA

O sistema identifica automaticamente conteÃºdos relacionados a:
- Diversidade, Equidade e IntegraÃ§Ã£o
- Diversidade, Equidade, InclusÃ£o e Pertencimento
- Diversidade, Equidade, InclusÃ£o, Acessibilidade
- Diversidade, Equidade, InclusÃ£o, Pertencimento
- Diversidade, Igualdade e InclusÃ£o
- Diversidade, Igualdade, InclusÃ£o e Acessibilidade
- Diversidade, Igualdade, InclusÃ£o, Pertencimento
- Equidade, Diversidade e InclusÃ£o
- InclusÃ£o, Diversidade, Equidade e Acessibilidade
- InclusÃ£o, Diversidade, Equidade, Acessibilidade
>>>>>>> a2555d3 (feat: implementaÃ§Ã£o completa com clean code e melhorias robustas)

## ğŸ› ï¸ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- pip

### InstalaÃ§Ã£o das DependÃªncias
```bash
pip install -r requirements.txt
```

## ğŸš€ Como Usar

<<<<<<< HEAD
### ExecuÃ§Ã£o BÃ¡sica
```bash
python scraper_unasus.py
```

### Monitoramento em Tempo Real
O scraper exibe logs detalhados durante a execuÃ§Ã£o:
```
Cursos jÃ¡ processados: 19
Arquivo de saÃ­da: unasus_ofertas_detalhadas.csv
Buscando ofertas do curso 44566...
  âœ… Oferta encontrada: 416699
  âœ… Oferta encontrada: 416329
  ğŸ“‹ Encontrados 2 links de ofertas encerradas
  âœ… Total de ofertas Ãºnicas encontradas: 2
  ğŸ” Extraindo dados da oferta 416699...
    âœ… Dados obtidos via API REST
    âœ… Vagas extraÃ­das: 10000
```

### VerificaÃ§Ã£o dos Resultados
```bash
python verificar_vagas.py
```

## ğŸ“ˆ Funcionalidades AvanÃ§adas

### ğŸ” **ExtraÃ§Ã£o de Ofertas Encerradas**
O scraper automaticamente:
- Detecta links para ofertas encerradas
- Acessa pÃ¡ginas especÃ­ficas de ofertas finalizadas
- Extrai dados completos mesmo de ofertas nÃ£o ativas

### ğŸ¯ **API REST para Dados Precisos**
- Utiliza a API oficial da UNA-SUS (`/rest/oferta/{id}`)
- Extrai dados estruturados em JSON
- Fallback para parsing HTML em caso de falha da API
- Headers otimizados para simular navegador real

### ğŸ“Š **AnÃ¡lise DEIA AutomÃ¡tica**
Detecta automaticamente descritores como:
- "Diversidade, Equidade e IntegraÃ§Ã£o"
- "Diversidade, Equidade, InclusÃ£o e Pertencimento"
- "InclusÃ£o, Diversidade, Equidade e Acessibilidade"
- E outros 7 descritores relacionados

### ğŸ’¾ **Sistema de Checkpoint**
- Salva progresso a cada 10 cursos processados
- Retoma automaticamente de onde parou
- Evita reprocessamento de dados jÃ¡ coletados

## ğŸ“ Estrutura do Projeto

```
una-sus/
â”œâ”€â”€ scraper_unasus.py                # Scraper principal
â”œâ”€â”€ requirements.txt                 # DependÃªncias
â”œâ”€â”€ README.md                        # DocumentaÃ§Ã£o
â”œâ”€â”€ .gitignore                       # Arquivos ignorados
â””â”€â”€ unasus_ofertas_detalhadas.csv    # Dataset gerado
```

## ğŸ”§ ConfiguraÃ§Ãµes

### VariÃ¡veis Principais
```python
# ConfiguraÃ§Ãµes de coleta
lote = 10                    # Salva a cada 10 cursos
timeout = 30                 # Timeout das requisiÃ§Ãµes
delay = 1                    # Delay entre requisiÃ§Ãµes

# Headers para API REST
api_headers = {
    "Accept": "application/json, text/javascript, */*; q=0.01",
    "X-Requested-With": "XMLHttpRequest",
    "Referer": url_oferta
}
=======
### 1. Scraper Principal
```bash
python scraper_unasus_incremental.py
```

**CaracterÃ­sticas:**
- Processamento incremental (salva a cada 10 registros)
- Sistema de checkpoint automÃ¡tico
- Logging detalhado em `logs/scraper_YYYYMMDD_HHMMSS.log`
- Arquivo de saÃ­da: `unasus_ofertas_detalhadas.csv`

### 2. Monitor em Tempo Real
```bash
python monitor_scraper.py
```

**Funcionalidades:**
- Status atual do scraper
- EstatÃ­sticas do arquivo CSV
- Ãšltimas entradas do log
- InformaÃ§Ãµes do checkpoint

### 3. Validador de Dados
```bash
python validar_dados.py
```

**AnÃ¡lises:**
- Estrutura dos dados
- ValidaÃ§Ã£o de cursos e ofertas
- EstatÃ­sticas DEIA
- RemoÃ§Ã£o de duplicatas
- Limpeza de registros vazios
- AnÃ¡lise de cursos incompletos

### 4. Teste de PaginaÃ§Ã£o
```bash
python teste_paginacao.py
```

**Debug:**
- Testa diferentes tokens de paginaÃ§Ã£o
- Compara resultados entre pÃ¡ginas
- Identifica problemas de paginaÃ§Ã£o

## ğŸ“ Estrutura do Projeto

```
unsa-sus/
â”œâ”€â”€ scraper_unasus_incremental.py  # Scraper principal
â”œâ”€â”€ monitor_scraper.py             # Monitor em tempo real
â”œâ”€â”€ validar_dados.py               # Validador de dados
â”œâ”€â”€ teste_paginacao.py             # Teste de paginaÃ§Ã£o
â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”œâ”€â”€ README.md                      # DocumentaÃ§Ã£o
â”œâ”€â”€ LICENSE                        # LicenÃ§a MIT
â”œâ”€â”€ setup.py                       # ConfiguraÃ§Ã£o do pacote
â”œâ”€â”€ pyproject.toml                 # ConfiguraÃ§Ã£o moderna
â”œâ”€â”€ .gitignore                     # Arquivos ignorados pelo Git
â”œâ”€â”€ logs/                          # Logs do scraper
â”œâ”€â”€ .github/workflows/             # CI/CD GitHub Actions
â”œâ”€â”€ .vscode/                       # ConfiguraÃ§Ãµes VS Code
â”œâ”€â”€ Dockerfile                     # ContainerizaÃ§Ã£o
â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o Docker
â””â”€â”€ .dockerignore                  # Arquivos ignorados no Docker
```

## ğŸ”§ ConfiguraÃ§Ãµes

### VariÃ¡veis de Ambiente (Opcional)
```bash
# ConfiguraÃ§Ãµes de logging
LOG_LEVEL=INFO
LOG_DIR=logs

# ConfiguraÃ§Ãµes do scraper
BATCH_SIZE=10
REQUEST_TIMEOUT=30
RETRY_DELAY=30
```

### Arquivos de ConfiguraÃ§Ã£o
- **checkpoint.json**: Progresso do scraper
- **unasus_ofertas_detalhadas.csv**: Dados coletados
- **logs/**: Arquivos de log com timestamp

## ğŸš€ ExecuÃ§Ã£o com Docker

### Usando Docker Compose
```bash
docker-compose up scraper
```

### Usando Docker diretamente
```bash
docker build -t unasus-scraper .
docker run -v $(pwd):/app unasus-scraper
>>>>>>> a2555d3 (feat: implementaÃ§Ã£o completa com clean code e melhorias robustas)
```

## ğŸ“Š Exemplo de SaÃ­da

<<<<<<< HEAD
```csv
co_seq_curso,no_curso,qt_carga_horaria_total,vagas,publico_alvo,local_oferta,formato,programas_governo
44538,"1Âº FormaÃ§Ã£o de Preceptores para o SUS",195,195,"Profissionais da saÃºde...",EAD,"Ensino a DistÃ¢ncia","UNA-SUS, EspecializaÃ§Ã£o"
44540,"2Âº FormaÃ§Ã£o de Preceptores para o SUS",195,195,"Profissionais da saÃºde...",EAD,"Ensino a DistÃ¢ncia","UNA-SUS, EspecializaÃ§Ã£o"
```

## ğŸš¨ Tratamento de Erros

O scraper inclui tratamento robusto de erros:
- **Timeout de conexÃ£o**: Retry automÃ¡tico apÃ³s 30 segundos
- **Falha na API**: Fallback para parsing HTML
- **Dados ausentes**: Campos preenchidos com string vazia
- **Ofertas sem vagas**: Log de aviso mantido

## ğŸ“ˆ EstatÃ­sticas de Coleta

### MÃ©tricas Finais (ExecuÃ§Ã£o Completa)
- **Cursos processados**: 552 cursos Ãºnicos (99.6% dos 554 disponÃ­veis)
- **Ofertas encontradas**: 1,656 ofertas
- **Taxa de sucesso vagas**: 100% (1,656/1,656)
- **Tempo de execuÃ§Ã£o**: ~2 horas
- **Arquivo final**: 1.28 MB com dados completos

### Logs de Progresso
```
PÃ¡gina 1 processada.
PÃ¡gina 2 processada.
...
Progresso salvo apÃ³s 20 cursos em unasus_ofertas_detalhadas.csv
```
=======
### Logs
- **Arquivo**: `logs/scraper_YYYYMMDD_HHMMSS.log`
- **NÃ­veis**: INFO, WARNING, ERROR, DEBUG
- **Formato**: Timestamp - NÃ­vel - Mensagem

### Checkpoint
- **Arquivo**: `checkpoint.json`
- **Dados**: PÃ¡gina atual, cursos processados, ofertas processadas, Ãºltimo token

### EstatÃ­sticas
- Total de cursos processados
- Total de ofertas encontradas
- Cursos com/sem DEIA
- Cursos incompletos (sem descriÃ§Ã£o)

## ğŸ” Exemplo de Dados

```csv
co_seq_curso,no_curso,qt_carga_horaria_total,ds_curso,tem_deia,deia_encontrado,id_oferta,vagas,publico_alvo,curso_incompleto
12345,Curso de AtenÃ§Ã£o Ã  Diversidade,60,"Curso focado em atenÃ§Ã£o Ã  diversidade...",Sim,"Diversidade, Equidade e InclusÃ£o",67890,100,"Profissionais de saÃºde",NÃ£o
```

## ğŸ›¡ï¸ Tratamento de Erros

### RecuperaÃ§Ã£o AutomÃ¡tica
- **Timeout de requisiÃ§Ãµes**: 30 segundos
- **Retry automÃ¡tico**: 30 segundos de espera
- **Checkpoint**: Salva progresso a cada lote
- **ValidaÃ§Ã£o**: Verifica dados antes de salvar

### Logs de Erro
- **Erros de conexÃ£o**: Registrados com retry automÃ¡tico
- **Dados invÃ¡lidos**: Marcados como "erro" no CSV
- **Cursos sem ofertas**: Registrados com flag especÃ­fico
>>>>>>> a2555d3 (feat: implementaÃ§Ã£o completa com clean code e melhorias robustas)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

<<<<<<< HEAD
Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ™ Agradecimentos

- UNA-SUS pela disponibilizaÃ§Ã£o dos dados
- Comunidade Python pelos recursos utilizados
- Contribuidores do projeto
=======
Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

### Problemas Comuns
1. **Erro de paginaÃ§Ã£o**: Use `teste_paginacao.py` para debug
2. **Dados incompletos**: Execute `validar_dados.py` para anÃ¡lise
3. **Scraper travado**: Verifique logs e checkpoint

### Logs Importantes
- **"Nenhum item encontrado"**: Fim dos dados
- **"Curso sem descriÃ§Ã£o"**: Curso marcado como incompleto
- **"Sem ofertas encontradas"**: Curso sem ofertas ativas/encerradas

## ğŸ”„ AtualizaÃ§Ãµes
>>>>>>> a2555d3 (feat: implementaÃ§Ã£o completa com clean code e melhorias robustas)

### VersÃ£o Atual
- **Clean Code**: CÃ³digo refatorado seguindo boas prÃ¡ticas
- **FunÃ§Ãµes Modulares**: SeparaÃ§Ã£o clara de responsabilidades
- **Tratamento Robusto**: Melhor gestÃ£o de erros e exceÃ§Ãµes
- **DocumentaÃ§Ã£o Completa**: README atualizado com todas as funcionalidades

<<<<<<< HEAD
**Desenvolvido com â¤ï¸ para facilitar a anÃ¡lise de dados educacionais em saÃºde pÃºblica.** 
=======
### PrÃ³ximas Melhorias
- Interface web para monitoramento
- API REST para consulta dos dados
- Dashboard com visualizaÃ§Ãµes
- IntegraÃ§Ã£o com bases de dados 
>>>>>>> a2555d3 (feat: implementaÃ§Ã£o completa com clean code e melhorias robustas)
