# Scraper UNA-SUS - Cursos e Ofertas

Um scraper robusto e eficiente para coletar dados de cursos e ofertas da plataforma UNA-SUS (Universidade Aberta do SUS), com foco especial na identificaÃ§Ã£o de conteÃºdos relacionados a DEIA (Diversidade, Equidade, InclusÃ£o e Acessibilidade).

## ğŸš€ Funcionalidades

### âœ¨ Principais Recursos
- **Scraping Inteligente**: Coleta dados de cursos e ofertas da UNA-SUS
- **AnÃ¡lise DEIA**: Identifica automaticamente conteÃºdos relacionados a Diversidade, Equidade, InclusÃ£o e Acessibilidade
- **Processamento Incremental**: Salva dados progressivamente para evitar perda de informaÃ§Ãµes
- **Sistema de Checkpoint**: Permite retomar o scraping de onde parou
- **Logging Detalhado**: Acompanhamento completo do progresso
- **ValidaÃ§Ã£o de Dados**: Verifica integridade e qualidade dos dados coletados
- **ExtraÃ§Ã£o de DescriÃ§Ãµes**: Busca descriÃ§Ãµes completas em pÃ¡ginas individuais dos cursos
- **Busca por Ofertas Encerradas**: Inclui ofertas que podem estar ocultas

### ğŸ”§ Ferramentas Auxiliares
- **Monitor em Tempo Real**: Acompanhe o progresso do scraper
- **Validador de Dados**: Analise e limpe os dados coletados
- **Teste de PaginaÃ§Ã£o**: Debug da API da UNA-SUS

## ğŸ“Š Dados Coletados

### InformaÃ§Ãµes dos Cursos
- **IdentificaÃ§Ã£o**: `co_seq_curso`, `id_curso`, `co_curso`
- **Dados BÃ¡sicos**: `no_curso` (nome), `qt_carga_horaria_total`
- **OrganizaÃ§Ã£o**: `co_seq_orgao`, `sg_orgao`, `no_orgao`
- **CaracterÃ­sticas**: `no_formato`, `no_nivel`, `no_modalidade`
- **MÃ­dia**: `ds_imagem`
- **Status**: `status`, `status_ordem`
- **DescriÃ§Ã£o**: `ds_curso` (extraÃ­da da pÃ¡gina do curso quando necessÃ¡rio)
- **Qualidade**: `curso_incompleto` (marca cursos sem descriÃ§Ã£o)

### InformaÃ§Ãµes das Ofertas
- **IdentificaÃ§Ã£o**: `id_oferta`, `codigo_oferta`
- **Detalhes**: `vagas`, `publico_alvo`, `local_oferta`
- **Formato**: `formato`
- **Programas**: `programas_governo`
- **ClassificaÃ§Ã£o**: `temas`, `decs`, `palavras_chave`
- **DescriÃ§Ã£o**: `descricao_oferta`

### AnÃ¡lise DEIA
- **Indicador**: `tem_deia` (Sim/NÃ£o)
- **Descritor**: `deia_encontrado` (descritor especÃ­fico encontrado)

### Campos de Controle
- **URL**: `url_oferta`
- **Erros**: `erro` (quando aplicÃ¡vel)

## ğŸ¯ Descritores DEIA

O sistema identifica automaticamente conteÃºdos relacionados a:
- Diversidade, Equidade e IntegraÃ§Ã£o
- Diversidade, Equidade, InclusÃ£o e Pertencimento
- Diversidade, Equidade, InclusÃ£o, Acessibilidade
- Diversidade, Equidade, InclusÃ£o, Pertencimento
- Diversidade, Igualdade e InclusÃ£o
- Diversidade, Igualdade, InclusÃ£o e Acessibilidade
- Diversidade, Igualdade, InclusÃ£o, Pertencimento
- Equidade, Diversidade e InclusÃ£o
- InclusÃ£o, Diversidade, Equidade e Acessibilidade
- InclusÃ£o, Diversidade, Equidade, Acessibilidade

## ğŸ› ï¸ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- pip

### InstalaÃ§Ã£o das DependÃªncias
```bash
pip install -r requirements.txt
```

## ğŸ“– Como Usar

### 1. Scraper Principal
```bash
python scraper_unasus_incremental.py
```

**CaracterÃ­sticas:**
- Processamento incremental (salva a cada 10 registros)
- Sistema de checkpoint automÃ¡tico
- Logging detalhado em `logs/scraper_YYYYMMDD_HHMMSS.log`
- Arquivo de saÃ­da: `unasus_ofertas_detalhadas.csv`

### 2. Monitor em Tempo Real
```bash
python monitor_scraper.py
```

**Funcionalidades:**
- Status atual do scraper
- EstatÃ­sticas do arquivo CSV
- Ãšltimas entradas do log
- InformaÃ§Ãµes do checkpoint

### 3. Validador de Dados
```bash
python validar_dados.py
```

**AnÃ¡lises:**
- Estrutura dos dados
- ValidaÃ§Ã£o de cursos e ofertas
- EstatÃ­sticas DEIA
- RemoÃ§Ã£o de duplicatas
- Limpeza de registros vazios
- AnÃ¡lise de cursos incompletos

### 4. Teste de PaginaÃ§Ã£o
```bash
python teste_paginacao.py
```

**Debug:**
- Testa diferentes tokens de paginaÃ§Ã£o
- Compara resultados entre pÃ¡ginas
- Identifica problemas de paginaÃ§Ã£o

## ğŸ“ Estrutura do Projeto

```
unsa-sus/
â”œâ”€â”€ scraper_unasus_incremental.py  # Scraper principal
â”œâ”€â”€ monitor_scraper.py             # Monitor em tempo real
â”œâ”€â”€ validar_dados.py               # Validador de dados
â”œâ”€â”€ teste_paginacao.py             # Teste de paginaÃ§Ã£o
â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”œâ”€â”€ README.md                      # DocumentaÃ§Ã£o
â”œâ”€â”€ LICENSE                        # LicenÃ§a MIT
â”œâ”€â”€ setup.py                       # ConfiguraÃ§Ã£o do pacote
â”œâ”€â”€ pyproject.toml                 # ConfiguraÃ§Ã£o moderna
â”œâ”€â”€ .gitignore                     # Arquivos ignorados pelo Git
â”œâ”€â”€ logs/                          # Logs do scraper
â”œâ”€â”€ .github/workflows/             # CI/CD GitHub Actions
â”œâ”€â”€ .vscode/                       # ConfiguraÃ§Ãµes VS Code
â”œâ”€â”€ Dockerfile                     # ContainerizaÃ§Ã£o
â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o Docker
â””â”€â”€ .dockerignore                  # Arquivos ignorados no Docker
```

## ğŸ”§ ConfiguraÃ§Ãµes

### VariÃ¡veis de Ambiente (Opcional)
```bash
# ConfiguraÃ§Ãµes de logging
LOG_LEVEL=INFO
LOG_DIR=logs

# ConfiguraÃ§Ãµes do scraper
BATCH_SIZE=10
REQUEST_TIMEOUT=30
RETRY_DELAY=30
```

### Arquivos de ConfiguraÃ§Ã£o
- **checkpoint.json**: Progresso do scraper
- **unasus_ofertas_detalhadas.csv**: Dados coletados
- **logs/**: Arquivos de log com timestamp

## ğŸš€ ExecuÃ§Ã£o com Docker

### Usando Docker Compose
```bash
docker-compose up scraper
```

### Usando Docker diretamente
```bash
docker build -t unasus-scraper .
docker run -v $(pwd):/app unasus-scraper
```

## ğŸ“ˆ Monitoramento

### Logs
- **Arquivo**: `logs/scraper_YYYYMMDD_HHMMSS.log`
- **NÃ­veis**: INFO, WARNING, ERROR, DEBUG
- **Formato**: Timestamp - NÃ­vel - Mensagem

### Checkpoint
- **Arquivo**: `checkpoint.json`
- **Dados**: PÃ¡gina atual, cursos processados, ofertas processadas, Ãºltimo token

### EstatÃ­sticas
- Total de cursos processados
- Total de ofertas encontradas
- Cursos com/sem DEIA
- Cursos incompletos (sem descriÃ§Ã£o)

## ğŸ” Exemplo de Dados

```csv
co_seq_curso,no_curso,qt_carga_horaria_total,ds_curso,tem_deia,deia_encontrado,id_oferta,vagas,publico_alvo,curso_incompleto
12345,Curso de AtenÃ§Ã£o Ã  Diversidade,60,"Curso focado em atenÃ§Ã£o Ã  diversidade...",Sim,"Diversidade, Equidade e InclusÃ£o",67890,100,"Profissionais de saÃºde",NÃ£o
```

## ğŸ›¡ï¸ Tratamento de Erros

### RecuperaÃ§Ã£o AutomÃ¡tica
- **Timeout de requisiÃ§Ãµes**: 30 segundos
- **Retry automÃ¡tico**: 30 segundos de espera
- **Checkpoint**: Salva progresso a cada lote
- **ValidaÃ§Ã£o**: Verifica dados antes de salvar

### Logs de Erro
- **Erros de conexÃ£o**: Registrados com retry automÃ¡tico
- **Dados invÃ¡lidos**: Marcados como "erro" no CSV
- **Cursos sem ofertas**: Registrados com flag especÃ­fico

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

### Problemas Comuns
1. **Erro de paginaÃ§Ã£o**: Use `teste_paginacao.py` para debug
2. **Dados incompletos**: Execute `validar_dados.py` para anÃ¡lise
3. **Scraper travado**: Verifique logs e checkpoint

### Logs Importantes
- **"Nenhum item encontrado"**: Fim dos dados
- **"Curso sem descriÃ§Ã£o"**: Curso marcado como incompleto
- **"Sem ofertas encontradas"**: Curso sem ofertas ativas/encerradas

## ğŸ”„ AtualizaÃ§Ãµes

### VersÃ£o Atual
- **Clean Code**: CÃ³digo refatorado seguindo boas prÃ¡ticas
- **FunÃ§Ãµes Modulares**: SeparaÃ§Ã£o clara de responsabilidades
- **Tratamento Robusto**: Melhor gestÃ£o de erros e exceÃ§Ãµes
- **DocumentaÃ§Ã£o Completa**: README atualizado com todas as funcionalidades

### PrÃ³ximas Melhorias
- Interface web para monitoramento
- API REST para consulta dos dados
- Dashboard com visualizaÃ§Ãµes
- IntegraÃ§Ã£o com bases de dados 